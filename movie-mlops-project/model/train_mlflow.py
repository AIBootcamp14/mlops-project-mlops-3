import logging
import os
import sys
import argparse
import json

import mlflow
import mlflow.xgboost
import pandas as pd
import xgboost as xgb
from dotenv import load_dotenv

# âœ… ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • ë° í™˜ê²½ ì„¤ì •
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.append(project_root)

# âœ… .env ë¡œë“œ (AWS ìê²© ì •ë³´ìš©)
load_dotenv()

from model.utils import get_config_value, load_data, load_feature_names

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def train_model(
    train_filepath: str,
    target_column: str,
    feature_names: list,
    xgb_params: dict,
    mlflow_tracking_uri: str,
    mlflow_experiment_name: str
) -> None:
    """
    XGBoost ëª¨ë¸ì„ í•™ìŠµí•˜ê³  MLflowì— ë¡œê¹…í•©ë‹ˆë‹¤.
    """
    logging.info("ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    mlflow.set_tracking_uri(mlflow_tracking_uri)
    mlflow.set_experiment(mlflow_experiment_name)

    run_name = f"XGBoost_Train_MaxDepth_{xgb_params.get('max_depth', 'default')}_Eta_{xgb_params.get('eta', 'default')}"
    with mlflow.start_run(run_name=run_name) as run:
        run_id = run.info.run_id
        logging.info(f"MLflow Run ID: {run_id}ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµ ì‹œì‘")

        try:
            train_df = load_data(train_filepath)

            # âœ… ëª¨ë“  ì»¬ëŸ¼ ì´ë¦„ì„ ë¬¸ìì—´ë¡œ ê°•ì œ ë³€í™˜
            train_df.columns = train_df.columns.astype(str)

            # âœ… ë””ë²„ê¹…: feature_namesì™€ ì»¬ëŸ¼ ë¹„êµ
            missing = [f for f in feature_names if f not in train_df.columns]
            if missing:
                logging.error(f"â— train_dfì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” featureë“¤: {missing}")
                logging.info(f"ğŸ’¡ train_df ì»¬ëŸ¼ ëª©ë¡: {train_df.columns.tolist()}")
                raise KeyError(f"{missing} not in train_df.columns")

            X_train = train_df[feature_names]
            y_train = train_df[target_column]

            logging.info(f"í•™ìŠµ ë°ì´í„° X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")

            mlflow.log_params(xgb_params)
            logging.info(f"MLflowì— íŒŒë¼ë¯¸í„° ë¡œê¹… ì™„ë£Œ: {xgb_params}")

            model = xgb.XGBRegressor(**xgb_params)
            logging.info("XGBoost ëª¨ë¸ í•™ìŠµ ì‹œì‘")
            model.fit(X_train, y_train)
            logging.info("XGBoost ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

            mlflow.xgboost.log_model(
                xgb_model=model,
                artifact_path="model",
            )
            logging.info("MLflowì— ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë¡œê¹… ì™„ë£Œ (ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡ ì œì™¸)")

            return

        except Exception as e:
            logging.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            mlflow.end_run(status="FAILED")
            raise


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="XGBoost ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--max_depth", type=int, help="XGBoost max_depth íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’ì„ ì˜¤ë²„ë¼ì´ë“œ)")
    parser.add_argument("--eta", type=float, help="XGBoost eta (learning_rate) íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’ì„ ì˜¤ë²„ë¼ì´ë“œ)")
    args = parser.parse_args()

    try:
        # âœ… config ê²½ë¡œ ì„¤ì •
        config_path = os.path.join(project_root, 'config', 'config.yaml')

        # âœ… config ê°’ ë¡œë”©
        processed_data_dir = get_config_value(config_path, 'data.processed_data_dir')
        train_data_file = get_config_value(config_path, 'data.train_data_file')
        feature_names_file = get_config_value(config_path, 'data.feature_names_file')
        target_column = get_config_value(config_path, 'model.target_column')
        base_xgb_params = get_config_value(config_path, 'model.xgboost_params')

        mlflow_tracking_uri = get_config_value(config_path, 'mlflow.tracking_uri')
        mlflow_experiment_name = get_config_value(config_path, 'mlflow.experiment_name')

        # âœ… ëª…ë ¹ì¤„ ì¸ì ë°˜ì˜
        current_xgb_params = base_xgb_params.copy()
        if args.max_depth is not None:
            current_xgb_params['max_depth'] = args.max_depth
            logging.info(f"max_depth ì¸ì ì˜¤ë²„ë¼ì´ë“œ: {args.max_depth}")
        if args.eta is not None:
            current_xgb_params['eta'] = args.eta
            logging.info(f"eta ì¸ì ì˜¤ë²„ë¼ì´ë“œ: {args.eta}")

        # âœ… feature_names ë¶ˆëŸ¬ì˜¤ê¸°
        feature_names = load_feature_names(
            os.path.join(project_root, processed_data_dir, feature_names_file)
        )

        # âœ… í•™ìŠµ ì‹¤í–‰
        train_model(
            train_filepath=os.path.join(project_root, processed_data_dir, train_data_file),
            target_column=target_column,
            feature_names=feature_names,
            xgb_params=current_xgb_params,
            mlflow_tracking_uri=mlflow_tracking_uri,
            mlflow_experiment_name=mlflow_experiment_name,
        )

        logging.info("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ. MLflowì— ê²°ê³¼ê°€ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        logging.error(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        sys.exit(1)
