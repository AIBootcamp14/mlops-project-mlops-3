import pandas as pd
import numpy as np
import json
from datetime import datetime
from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

class TMDBDataPreprocessor:
    """TMDB ì˜í™” ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.minmax_scaler = MinMaxScaler()
        self.label_encoders = {}
        
    def step1_load_and_inspect(self, json_file_path):
        """1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ íƒìƒ‰"""
        print("=== STEP 1: ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰ ===")
        
        # JSON íŒŒì¼ ë¡œë“œ
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ì˜í™” ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        movies = data.get('movies', data) if isinstance(data, dict) else data
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(movies)
        
        print(f"ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}")
        print(f"ì»¬ëŸ¼: {list(df.columns)}")
        print(f"\nê²°ì¸¡ê°’ í˜„í™©:")
        print(df.isnull().sum())
        
        print(f"\nê¸°ë³¸ í†µê³„:")
        if 'vote_average' in df.columns:
            print(f"í‰ì  ë²”ìœ„: {df['vote_average'].min()} ~ {df['vote_average'].max()}")
            print(f"í‰ì  í‰ê· : {df['vote_average'].mean():.2f}")
        
        return df
    
    def step2_data_cleaning(self, df):
        """2ë‹¨ê³„: ë°ì´í„° ì •ì œ"""
        print("\n=== STEP 2: ë°ì´í„° ì •ì œ ===")
        
        original_size = len(df)
        
        # 1. ì¤‘ë³µ ì œê±°
        df = df.drop_duplicates(subset=['id'], keep='first')
        print(f"ì¤‘ë³µ ì œê±°: {original_size} â†’ {len(df)}")
        
        # 2. í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ê²°ì¸¡ê°’ ì œê±°
        required_columns = ['id', 'vote_average', 'vote_count', 'popularity']
        missing_required = [col for col in required_columns if col not in df.columns]
        
        if missing_required:
            print(f"âš ï¸ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_required}")
            return None
        
        # 3. ì´ìƒê°’ ì œê±°
        # í‰ì ì´ 0ì´ê±°ë‚˜ íˆ¬í‘œìˆ˜ê°€ ë„ˆë¬´ ì ì€ ì˜í™” ì œê±°
        before_filter = len(df)
        df = df[df['vote_average'] > 0]
        df = df[df['vote_count'] >= 10]  # ìµœì†Œ 10í‘œ ì´ìƒ
        df = df[df['vote_average'] <= 10]  # í‰ì  10 ì´í•˜
        print(f"ì´ìƒê°’ ì œê±°: {before_filter} â†’ {len(df)}")
        
        # 4. ë°ì´í„° íƒ€ì… ì •ë¦¬
        numeric_columns = ['vote_average', 'vote_count', 'popularity']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # 5. ê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰ ì œê±°
        df = df.dropna(subset=required_columns)
        print(f"ìµœì¢… ì •ì œëœ ë°ì´í„°: {len(df)}ê°œ ì˜í™”")
        
        return df
    
    def step3_feature_engineering(self, df):
        """3ë‹¨ê³„: íŠ¹ì„± ê³µí•™"""
        print("\n=== STEP 3: íŠ¹ì„± ê³µí•™ ===")
        
        # ë‚ ì§œ ê´€ë ¨ íŠ¹ì„±
        if 'release_date' in df.columns:
            df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
            df['release_year'] = df['release_date'].dt.year
            df['release_month'] = df['release_date'].dt.month
            df['release_quarter'] = df['release_date'].dt.quarter
            
            # ì˜í™” ë‚˜ì´ (2024ë…„ ê¸°ì¤€)
            current_year = 2024
            df['movie_age'] = current_year - df['release_year']
            
            # ì‹œì¦Œì„± íŠ¹ì„±
            df['is_summer_release'] = df['release_month'].isin([6,7,8]).astype(int)
            df['is_holiday_release'] = df['release_month'].isin([11,12]).astype(int)
            df['is_spring_release'] = df['release_month'].isin([3,4,5]).astype(int)
        
        # ì¥ë¥´ ê´€ë ¨ íŠ¹ì„±
        if 'genre_ids' in df.columns:
            # genre_idsê°€ ë¬¸ìì—´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            def parse_genre_ids(genre_ids):
                if isinstance(genre_ids, str):
                    try:
                        return json.loads(genre_ids.replace("'", '"'))
                    except:
                        return []
                elif isinstance(genre_ids, list):
                    return genre_ids
                else:
                    return []
            
            df['genre_ids'] = df['genre_ids'].apply(parse_genre_ids)
            df['primary_genre'] = df['genre_ids'].apply(lambda x: x[0] if len(x) > 0 else 0)
            df['genre_count'] = df['genre_ids'].apply(len)
            
            # ì£¼ìš” ì¥ë¥´ ì›í•« ì¸ì½”ë”©
            major_genres = {
                28: 'Action', 12: 'Adventure', 16: 'Animation', 35: 'Comedy',
                80: 'Crime', 99: 'Documentary', 18: 'Drama', 10751: 'Family',
                14: 'Fantasy', 36: 'History', 27: 'Horror', 10402: 'Music',
                9648: 'Mystery', 10749: 'Romance', 878: 'Science Fiction',
                53: 'Thriller', 10752: 'War', 37: 'Western'
            }
            
            for genre_id, genre_name in major_genres.items():
                df[f'is_{genre_name.lower().replace(" ", "_")}'] = df['genre_ids'].apply(
                    lambda x: 1 if genre_id in x else 0
                )
        
        # ì–¸ì–´ ê´€ë ¨ íŠ¹ì„±
        if 'original_language' in df.columns:
            df['is_english'] = (df['original_language'] == 'en').astype(int)
            df['is_korean'] = (df['original_language'] == 'ko').astype(int)
            df['is_non_english'] = (df['original_language'] != 'en').astype(int)
        
        # ì¸ê¸°ë„ ê´€ë ¨ íŠ¹ì„±
        df['log_popularity'] = np.log1p(df['popularity'])
        df['log_vote_count'] = np.log1p(df['vote_count'])
        
        # íˆ¬í‘œ íš¨ìœ¨ì„± (ì¸ê¸°ë„ ëŒ€ë¹„ íˆ¬í‘œìˆ˜)
        df['vote_efficiency'] = df['vote_count'] / (df['popularity'] + 1)
        
        # í‰ì  êµ¬ê°„
        df['rating_tier'] = pd.cut(df['vote_average'], 
                                  bins=[0, 5, 6.5, 8, 10], 
                                  labels=['Low', 'Medium', 'High', 'Excellent'])
        
        # ì¸ê¸°ë„ êµ¬ê°„
        df['popularity_tier'] = pd.qcut(df['popularity'], 
                                       q=5, 
                                       labels=['Very_Low', 'Low', 'Medium', 'High', 'Very_High'],
                                       duplicates='drop')
        
        # ì½˜í…ì¸  ê´€ë ¨ íŠ¹ì„±
        if 'adult' in df.columns:
            df['is_adult'] = df['adult'].astype(int)
        
        # ì œëª© ê´€ë ¨ íŠ¹ì„±
        if 'title' in df.columns:
            df['title_length'] = df['title'].str.len()
            df['title_word_count'] = df['title'].str.split().str.len()
        
        # ì¤„ê±°ë¦¬ ê´€ë ¨ íŠ¹ì„±
        if 'overview' in df.columns:
            df['overview_length'] = df['overview'].fillna('').str.len()
            df['has_overview'] = (df['overview'].notna() & (df['overview'] != '')).astype(int)
        
        # ì´ë¯¸ì§€ ê´€ë ¨ íŠ¹ì„±
        if 'poster_path' in df.columns:
            df['has_poster'] = df['poster_path'].notna().astype(int)
        if 'backdrop_path' in df.columns:
            df['has_backdrop'] = df['backdrop_path'].notna().astype(int)
        
        print(f"íŠ¹ì„± ê³µí•™ ì™„ë£Œ. ì´ íŠ¹ì„± ìˆ˜: {len(df.columns)}")
        
        return df
    
    def step4_handle_missing_values(self, df):
        """4ë‹¨ê³„: ê²°ì¸¡ê°’ ì²˜ë¦¬"""
        print("\n=== STEP 4: ê²°ì¸¡ê°’ ì²˜ë¦¬ ===")
        
        print("ê²°ì¸¡ê°’ ì²˜ë¦¬ ì „:")
        missing_before = df.isnull().sum()
        print(missing_before[missing_before > 0])
        
        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ê²°ì¸¡ê°’ ì²˜ë¦¬
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            if df[col].isnull().sum() > 0:
                if col in ['release_year', 'movie_age']:
                    # ì—°ë„ ê´€ë ¨ì€ ì¤‘ì•™ê°’ìœ¼ë¡œ
                    df[col] = df[col].fillna(df[col].median())
                else:
                    # ë‚˜ë¨¸ì§€ëŠ” í‰ê· ìœ¼ë¡œ
                    df[col] = df[col].fillna(df[col].mean())
        
        # ë²”ì£¼í˜• ì»¬ëŸ¼ ê²°ì¸¡ê°’ ì²˜ë¦¬
        categorical_columns = df.select_dtypes(include=['object', 'category']).columns
        for col in categorical_columns:
            if df[col].isnull().sum() > 0:
                if col in ['rating_tier', 'popularity_tier']:
                    df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else 'Unknown')
                else:
                    df[col] = df[col].fillna('Unknown')
        
        print("ê²°ì¸¡ê°’ ì²˜ë¦¬ í›„:")
        missing_after = df.isnull().sum()
        print(missing_after[missing_after > 0])
        
        return df
    
    def step5_feature_scaling(self, df, target_column='vote_average'):
        """5ë‹¨ê³„: íŠ¹ì„± ìŠ¤ì¼€ì¼ë§"""
        print("\n=== STEP 5: íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ===")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬
        if target_column in df.columns:
            y = df[target_column].copy()
            X = df.drop(columns=[target_column])
        else:
            print(f"âš ï¸ íƒ€ê²Ÿ ì»¬ëŸ¼ '{target_column}'ì´ ì—†ìŠµë‹ˆë‹¤.")
            return df
        
        # ìˆ˜ì¹˜í˜• íŠ¹ì„±ë§Œ ì„ íƒ
        numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
        
        # ID, ë°”ì´ë„ˆë¦¬ íŠ¹ì„± ì œì™¸
        exclude_features = ['id', 'content_id'] + [col for col in numeric_features if X[col].nunique() <= 2]
        numeric_features = [col for col in numeric_features if col not in exclude_features]
        
        print(f"ìŠ¤ì¼€ì¼ë§ ëŒ€ìƒ íŠ¹ì„±: {len(numeric_features)}ê°œ")
        
        # StandardScaler ì ìš©
        X_numeric_scaled = self.scaler.fit_transform(X[numeric_features])
        X_numeric_scaled_df = pd.DataFrame(X_numeric_scaled, 
                                          columns=[f"{col}_scaled" for col in numeric_features],
                                          index=X.index)
        
        # ë²”ì£¼í˜• íŠ¹ì„± ì¸ì½”ë”©
        categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()
        
        for col in categorical_features:
            if col not in self.label_encoders:
                self.label_encoders[col] = LabelEncoder()
            X[f"{col}_encoded"] = self.label_encoders[col].fit_transform(X[col].astype(str))
        
        # ìµœì¢… íŠ¹ì„± ê²°í•©
        final_features = []
        
        # ì›ë³¸ ìˆ˜ì¹˜í˜• íŠ¹ì„± (ë°”ì´ë„ˆë¦¬, ID í¬í•¨)
        original_numeric = [col for col in X.select_dtypes(include=[np.number]).columns 
                           if col not in numeric_features]
        final_features.extend(original_numeric)
        
        # ìŠ¤ì¼€ì¼ë§ëœ íŠ¹ì„±
        final_features.extend([f"{col}_scaled" for col in numeric_features])
        
        # ì¸ì½”ë”©ëœ ë²”ì£¼í˜• íŠ¹ì„±
        final_features.extend([f"{col}_encoded" for col in categorical_features])
        
        # ìµœì¢… ë°ì´í„°ì…‹ êµ¬ì„±
        X_final = pd.concat([
            X[original_numeric],
            X_numeric_scaled_df,
            X[[f"{col}_encoded" for col in categorical_features]]
        ], axis=1)
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ì¶”ê°€
        final_df = pd.concat([X_final, y], axis=1)
        
        print(f"ìµœì¢… íŠ¹ì„± ìˆ˜: {len(X_final.columns)}")
        
        return final_df
    
    def step6_train_test_split(self, df, target_column='vote_average', test_size=0.2):
        """6ë‹¨ê³„: í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• """
        print("\n=== STEP 6: ë°ì´í„° ë¶„í•  ===")
        
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        X = df.drop(columns=[target_column])
        y = df[target_column]
        
        # ì‹œê°„ìˆœ ë¶„í•  (release_yearê°€ ìˆëŠ” ê²½ìš°)
        if 'release_year' in df.columns:
            # ìµœì‹  20%ì˜ ì˜í™”ë¥¼ í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ
            year_threshold = df['release_year'].quantile(0.8)
            
            train_mask = df['release_year'] <= year_threshold
            test_mask = df['release_year'] > year_threshold
            
            X_train, X_test = X[train_mask], X[test_mask]
            y_train, y_test = y[train_mask], y[test_mask]
            
            print(f"ì‹œê°„ìˆœ ë¶„í•  ì ìš© (ê¸°ì¤€ì—°ë„: {year_threshold})")
        else:
            # ëœë¤ ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=None
            )
            print("ëœë¤ ë¶„í•  ì ìš©")
        
        print(f"í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")
        print(f"í•™ìŠµ ë°ì´í„° í‰ì  ë¶„í¬: {y_train.describe()}")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ì  ë¶„í¬: {y_test.describe()}")
        
        return X_train, X_test, y_train, y_test
    
    def get_preprocessing_summary(self, df):
        """ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½"""
        print("\n=== ì „ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½ ===")
        print(f"ìµœì¢… ë°ì´í„° í¬ê¸°: {df.shape}")
        print(f"íŠ¹ì„± ìˆ˜: {len(df.columns) - 1}")  # íƒ€ê²Ÿ ì œì™¸
        print(f"í‰ì  ë¶„í¬:")
        print(df['vote_average'].describe())
        
        # íŠ¹ì„±ë³„ íƒ€ì… í™•ì¸
        print(f"\níŠ¹ì„± íƒ€ì…ë³„ ê°œìˆ˜:")
        print(df.dtypes.value_counts())
        
        return df
    
    def run_full_pipeline(self, json_file_path, target_column='vote_average'):
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸ¬ TMDB ì˜í™” í‰ì  ì˜ˆì¸¡ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        print("=" * 50)
        
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        df = self.step1_load_and_inspect(json_file_path)
        if df is None:
            return None
            
        df = self.step2_data_cleaning(df)
        if df is None:
            return None
            
        df = self.step3_feature_engineering(df)
        df = self.step4_handle_missing_values(df)
        df = self.step5_feature_scaling(df, target_column)
        
        # ìµœì¢… ìš”ì•½
        df = self.get_preprocessing_summary(df)
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        X_train, X_test, y_train, y_test = self.step6_train_test_split(df, target_column)
        
        print("\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        
        return {
            'processed_df': df,
            'X_train': X_train,
            'X_test': X_test, 
            'y_train': y_train,
            'y_test': y_test,
            'feature_names': X_train.columns.tolist()
        }
    
    def save_processed_data(self, results, output_dir='./result'):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        # ì „ì²´ ë°ì´í„°ì…‹ ì €ì¥
        results['processed_df'].to_csv(f'{output_dir}/tmdb_processed_full.csv', index=False)
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥
        pd.concat([results['X_train'], results['y_train']], axis=1).to_csv(
            f'{output_dir}/tmdb_train.csv', index=False
        )
        pd.concat([results['X_test'], results['y_test']], axis=1).to_csv(
            f'{output_dir}/tmdb_test.csv', index=False
        )
        
        # íŠ¹ì„± ëª©ë¡ ì €ì¥
        with open(f'{output_dir}/feature_names.json', 'w') as f:
            json.dump(results['feature_names'], f, indent=2)
        
        print(f"ğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ {output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    preprocessor = TMDBDataPreprocessor()
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    results = preprocessor.run_full_pipeline('./result/popular.json')
    
    if results:
        # ê²°ê³¼ ì €ì¥ (ìë™)
        preprocessor.save_processed_data(results)
        
        # ì¶”ê°€ ìˆ˜ë™ ì €ì¥ (í™•ì‹¤íˆ í•˜ê¸° ìœ„í•´)
        print("\nğŸ’¾ CSV íŒŒì¼ ì €ì¥ í™•ì¸:")
        
        # ê°œë³„ DataFrame ì €ì¥
        results['processed_df'].to_csv('./result/full_dataset.csv', index=False, encoding='utf-8')
        print("âœ… ì „ì²´ ë°ì´í„°ì…‹: ./result/full_dataset.csv")
        
        results['X_train'].to_csv('./result/X_train.csv', index=False, encoding='utf-8')
        results['y_train'].to_csv('./result/y_train.csv', index=False, encoding='utf-8')
        print("âœ… í•™ìŠµ ë°ì´í„°: ./result/X_train.csv, ./result/y_train.csv")
        
        results['X_test'].to_csv('./result/X_test.csv', index=False, encoding='utf-8')
        results['y_test'].to_csv('./result/y_test.csv', index=False, encoding='utf-8')
        print("âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°: ./result/X_test.csv, ./result/y_test.csv")
        
        print(f"\nğŸ“Š ì €ì¥ëœ ë°ì´í„° ì •ë³´:")
        print(f"- ì „ì²´ ë°ì´í„° í¬ê¸°: {results['processed_df'].shape}")
        print(f"- í•™ìŠµ ë°ì´í„° í¬ê¸°: {results['X_train'].shape}")
        print(f"- í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {results['X_test'].shape}")
        print(f"- íŠ¹ì„± ê°œìˆ˜: {len(results['feature_names'])}")
        
        # ì €ì¥ëœ íŒŒì¼ í¬ê¸° í™•ì¸
        import os
        if os.path.exists('./result/full_dataset.csv'):
            size = os.path.getsize('./result/full_dataset.csv') / 1024 / 1024
            print(f"- íŒŒì¼ í¬ê¸°: {size:.2f} MB")