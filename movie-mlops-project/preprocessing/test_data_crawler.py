import os
import json
import time
import requests
from datetime import datetime

class TestDataCrawler:
    def __init__(
        self, region="KR", 
        language="ko-KR", 
        image_language="ko", 
        request_interval_seconds=0.4
    ):
        self._base_url = os.environ.get("TMDB_BASE_URL")
        self._api_key = os.environ.get("TMDB_API_KEY")
        self._region = region
        self._language = language
        self._image_language = image_language
        self._request_interval_seconds = request_interval_seconds
    
    def get_popular_movies(self, page):
        """ì¸ê¸° ì˜í™” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        params = {
            "api_key": self._api_key,
            "language": self._language,
            "region": self._region,
            "page": page
        }
        response = requests.get(f"{self._base_url}/popular", params=params)
        if not response.status_code == 200:
            print(f"âŒ Error fetching popular page {page}: Status {response.status_code}")
            return []
        return json.loads(response.text)["results"]
    
    def get_upcoming_movies(self, page):
        """ê°œë´‰ ì˜ˆì • ì˜í™” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        params = {
            "api_key": self._api_key,
            "language": self._language,
            "region": self._region,
            "page": page
        }
        response = requests.get(f"{self._base_url}/upcoming", params=params)
        if not response.status_code == 200:
            print(f"âŒ Error fetching upcoming page {page}: Status {response.status_code}")
            return []
        return json.loads(response.text)["results"]
    
    def collect_test_popular_extended(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° 1: ì¸ê¸° ì˜í™” 21-30í˜ì´ì§€ (200í¸)"""
        print("\nğŸ“Š Collecting Test Data 1: Popular Extended (pages 21-30)")
        print("=" * 50)
        
        movies = []
        for page in range(21, 31):  # 21-30 í˜ì´ì§€
            print(f"ğŸ“„ Crawling popular page {page}/30... ", end="")
            
            page_movies = self.get_popular_movies(page)
            if page_movies:
                movies.extend(page_movies)
                print(f"âœ… Got {len(page_movies)} movies (Total: {len(movies)})")
            else:
                print(f"âš ï¸ No movies found")
            
            if page < 30:
                time.sleep(self._request_interval_seconds)
        
        print(f"âœ¨ Collected {len(movies)} popular extended movies")
        return movies
    
    def collect_test_upcoming_by_rating(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° 2, 3: ê°œë´‰ ì˜ˆì • ì˜í™” í‰ì  ìœ ë¬´ë¡œ ë¶„ë¥˜"""
        print("\nğŸ“Š Collecting Test Data 2 & 3: Upcoming Movies (pages 1-5)")
        print("=" * 50)
        
        movies_with_ratings = []
        movies_without_ratings = []
        
        for page in range(1, 6):  # 1-5 í˜ì´ì§€
            print(f"ğŸ“„ Crawling upcoming page {page}/5... ", end="")
            
            page_movies = self.get_upcoming_movies(page)
            if page_movies:
                # í‰ì  ìœ ë¬´ë¡œ ë¶„ë¥˜
                for movie in page_movies:
                    if movie.get('vote_count', 0) > 0 and movie.get('vote_average', 0) > 0:
                        movies_with_ratings.append(movie)
                    else:
                        movies_without_ratings.append(movie)
                
                print(f"âœ… Got {len(page_movies)} movies (Rated: {len(movies_with_ratings)}, Unrated: {len(movies_without_ratings)})")
            else:
                print(f"âš ï¸ No movies found")
            
            if page < 5:
                time.sleep(self._request_interval_seconds)
        
        print(f"âœ¨ Collected {len(movies_with_ratings)} rated upcoming movies")
        print(f"âœ¨ Collected {len(movies_without_ratings)} unrated upcoming movies")
        
        # ëª©í‘œ ìˆ˜ëŸ‰ì— ë§ê²Œ ì¡°ì •
        movies_with_ratings = movies_with_ratings[:100]  # ìµœëŒ€ 100í¸
        movies_without_ratings = movies_without_ratings[:50]  # ìµœëŒ€ 50í¸
        
        return movies_with_ratings, movies_without_ratings
    
    @staticmethod
    def save_movies_to_json_file(movies, dst="./result", filename="test_data"):
        """ì˜í™” ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        os.makedirs(dst, exist_ok=True)
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        data = {
            "movies": movies,
            "count": len(movies),
            "crawled_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "data_type": filename
        }
        
        file_path = os.path.join(dst, f"{filename}.json")
        
        with open(file_path, "w", encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ Movies saved to: {file_path}")
        print(f"ğŸ“Š File size: {os.path.getsize(file_path) / 1024:.2f} KB")
        
        # ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
        if movies:
            avg_rating = sum(movie.get('vote_average', 0) for movie in movies) / len(movies)
            print(f"ğŸ“ˆ Average rating: {avg_rating:.2f}")


if __name__ == "__main__":
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    if not os.environ.get("TMDB_API_KEY"):
        print("âŒ TMDB_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì •í•˜ì„¸ìš”:")
        print("export TMDB_API_KEY='your_api_key_here'")
        print("export TMDB_BASE_URL='https://api.themoviedb.org/3/movie'")
        exit(1)
    
    if not os.environ.get("TMDB_BASE_URL"):
        print("âŒ TMDB_BASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("export TMDB_BASE_URL='https://api.themoviedb.org/3/movie'")
        exit(1)
    
    print("ğŸš€ TMDB Test Data Crawler Started")
    print("=" * 50)
    
    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
    crawler = TestDataCrawler()
    
    try:
        # 1. ì¸ê¸° ì˜í™” 21-30í˜ì´ì§€ ìˆ˜ì§‘
        popular_extended = crawler.collect_test_popular_extended()
        if popular_extended:
            TestDataCrawler.save_movies_to_json_file(
                popular_extended, 
                filename="test_popular_extended"
            )
        
        print("\n" + "=" * 50)
        
        # 2, 3. ê°œë´‰ ì˜ˆì • ì˜í™” í‰ì  ìœ ë¬´ë¡œ ë¶„ë¥˜í•˜ì—¬ ìˆ˜ì§‘
        upcoming_rated, upcoming_unrated = crawler.collect_test_upcoming_by_rating()
        
        if upcoming_rated:
            TestDataCrawler.save_movies_to_json_file(
                upcoming_rated, 
                filename="test_upcoming_rated"
            )
        
        if upcoming_unrated:
            TestDataCrawler.save_movies_to_json_file(
                upcoming_unrated, 
                filename="test_upcoming_unrated"
            )
        
        # ì „ì²´ ìš”ì•½
        print("\n" + "=" * 50)
        print("ğŸ“Š Test Data Collection Summary:")
        print(f"   1. Popular Extended: {len(popular_extended)} movies")
        print(f"   2. Upcoming Rated: {len(upcoming_rated)} movies")
        print(f"   3. Upcoming Unrated: {len(upcoming_unrated)} movies")
        print(f"   Total Test Data: {len(popular_extended) + len(upcoming_rated) + len(upcoming_unrated)} movies")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Crawling interrupted by user")
    except Exception as e:
        print(f"\nâŒ Error occurred: {str(e)}")
        import traceback
        traceback.print_exc()
    
    print("\nâœ… Test Data Crawler finished!")