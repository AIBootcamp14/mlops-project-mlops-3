from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import logging
import sys
from datetime import datetime
import os

# ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# ì˜ˆì¸¡ ì„œë¹„ìŠ¤ import
from services.prediction_service import SimplePredictionService

# ============================================================================
# ðŸ”§ í†µí•© ë¡œê¹… ì„¤ì • (uvicornê³¼ í†µí•©)
# ============================================================================
def setup_logging():
    """í†µí•© ë¡œê¹… ì„¤ì • - uvicornê³¼ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ë¥¼ ëª¨ë‘ ì½˜ì†”ì— í‘œì‹œ"""
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬ ìƒì„±
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    
    # ë¡œê·¸ í¬ë§· ì„¤ì • (ì‹œê°„, ëª¨ë“ˆëª…, ë ˆë²¨, ë©”ì‹œì§€)
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    console_handler.setFormatter(formatter)
    
    # ë£¨íŠ¸ ë¡œê±°ì— í•¸ë“¤ëŸ¬ ì¶”ê°€
    root_logger.addHandler(console_handler)
    
    # ê° ëª¨ë“ˆë³„ ë¡œê±° ì„¤ì •
    loggers = [
        'main',
        'services.prediction_service', 
        'services.mlflow_service',
        'services.data_service',
        'uvicorn.access',
        'uvicorn.error'
    ]
    
    for logger_name in loggers:
        logger = logging.getLogger(logger_name)
        logger.setLevel(logging.INFO)
        logger.propagate = True  # ë¶€ëª¨ ë¡œê±°ë¡œ ì „íŒŒ
    
    print("ðŸ”§ í†µí•© ë¡œê¹… ì„¤ì • ì™„ë£Œ!")

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œìž‘ ì „ ë¡œê¹… ì„¤ì •
setup_logging()

# í˜„ìž¬ ëª¨ë“ˆìš© ë¡œê±° ìƒì„±
logger = logging.getLogger(__name__)

# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = FastAPI(
    title="ðŸŽ¬ Movie Rating Prediction API", 
    description="TMDB ë°ì´í„°ë¥¼ í™œìš©í•œ ì˜í™” í‰ì  ì˜ˆì¸¡ ì„œë¹„ìŠ¤ (MLflow + XGBoost)",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ê°ì²´
prediction_service = None

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œìž‘ì‹œ ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° ì˜ˆì¸¡ ì‹¤í–‰"""
    global prediction_service
    
    logger.info("=" * 80)
    logger.info("ðŸš€ Movie Rating Prediction FastAPI ì„œë²„ ì‹œìž‘!")
    logger.info("=" * 80)
    
    try:
        # 1ë‹¨ê³„: ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ìƒì„± ë° ì´ˆê¸°í™”
        logger.info("ðŸ“¦ 1ë‹¨ê³„: SimplePredictionService ê°ì²´ ìƒì„± ì¤‘...")
        prediction_service = SimplePredictionService()
        logger.info("âœ… ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ê°ì²´ ìƒì„± ì™„ë£Œ")
        
        logger.info("ðŸ¤– 2ë‹¨ê³„: MLflow Production ëª¨ë¸ & CSV ë°ì´í„° ë¡œë”© ì¤‘...")
        init_result = prediction_service.initialize()
        
        if not init_result['success']:
            logger.error(f"âŒ ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {init_result['message']}")
            logger.error("ðŸ’¡ í•´ê²° ë°©ë²•:")
            logger.error("   1. MLflow ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸: http://localhost:5001")
            logger.error("   2. Production ëª¨ë¸ì´ ë“±ë¡ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸")
            logger.error("   3. tmdb_test.csv íŒŒì¼ ê²½ë¡œ í™•ì¸")
            return
        
        logger.info("âœ… ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")
        logger.info(f"   ðŸ·ï¸ ëª¨ë¸ ë²„ì „: {init_result.get('model_version')}")
        logger.info(f"   ðŸ“Š ë¡œë“œëœ ì˜í™” ìˆ˜: {init_result.get('data_count'):,}ê°œ")
        
        # 2ë‹¨ê³„: ì „ì²´ ì˜í™” ì˜ˆì¸¡ ì‹¤í–‰
        logger.info("ðŸŽ¯ 3ë‹¨ê³„: ì „ì²´ ì˜í™” ë°ì´í„° ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
        logger.info("   (ì´ ê³¼ì •ì€ ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ëª‡ ì´ˆ~ëª‡ ë¶„ ì†Œìš”ë©ë‹ˆë‹¤)")
        
        pred_result = prediction_service.predict_all()
        
        if pred_result['success']:
            logger.info("ðŸŽ‰ ì „ì²´ ì˜ˆì¸¡ ì™„ë£Œ!")
            logger.info(f"   ðŸ“ˆ ì˜ˆì¸¡ ì™„ë£Œëœ ì˜í™”: {pred_result['sample_count']:,}ê°œ")
            
            # ìƒìœ„ 5ê°œ ì˜í™” ë¯¸ë¦¬ë³´ê¸°
            top_movies = prediction_service.get_top_movies(5)
            if top_movies['available']:
                logger.info("ðŸ† ì˜ˆì¸¡ í‰ì  ìƒìœ„ 5ê°œ ì˜í™” ë¯¸ë¦¬ë³´ê¸°:")
                for movie in top_movies['top_movies']:
                    logger.info(f"   {movie['rank']}ìœ„. ì˜í™” ID {movie['movie_id']}: â­ {movie['predicted_rating']:.2f}")
            
        else:
            logger.error(f"âŒ ì˜ˆì¸¡ ì‹¤í–‰ ì‹¤íŒ¨: {pred_result['message']}")
            return
            
        # ìµœì¢… ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        status = prediction_service.get_status()
        logger.info("ðŸ“Š 4ë‹¨ê³„: ì„œë¹„ìŠ¤ ìµœì¢… ìƒíƒœ í™•ì¸")
        logger.info(f"   ì„œë¹„ìŠ¤ ì¤€ë¹„: {'âœ… ì™„ë£Œ' if status['service_ready'] else 'âŒ ì‹¤íŒ¨'}")
        logger.info(f"   ëª¨ë¸ ë¡œë“œ: {'âœ… ì™„ë£Œ' if status['model_loaded'] else 'âŒ ì‹¤íŒ¨'}")
        logger.info(f"   ë°ì´í„° ë¡œë“œ: {'âœ… ì™„ë£Œ' if status['data_loaded'] else 'âŒ ì‹¤íŒ¨'}")
        logger.info(f"   ì˜ˆì¸¡ ì™„ë£Œ: {'âœ… ì™„ë£Œ' if status['predictions_available'] else 'âŒ ì‹¤íŒ¨'}")
        
        logger.info("=" * 80)
        logger.info("ðŸŽŠ Movie Rating Prediction API ì„œë²„ ì¤€ë¹„ ì™„ë£Œ!")
        logger.info("ðŸŒ API ë¬¸ì„œ: http://localhost:8000/docs")
        logger.info("ðŸ“Š Streamlit ëŒ€ì‹œë³´ë“œ: streamlit run streamlit_app.py")
        logger.info("=" * 80)
            
    except Exception as e:
        logger.error("=" * 80)
        logger.error(f"âŒ ì„œë²„ ì‹œìž‘ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.error("ðŸ’¡ ë””ë²„ê¹… ì •ë³´:")
        logger.error(f"   ì˜¤ë¥˜ íƒ€ìž…: {type(e).__name__}")
        logger.error(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
        logger.error("=" * 80)
        import traceback
        logger.error("ðŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        logger.error(traceback.format_exc())

# ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ë“¤...
@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - API ê¸°ë³¸ ì •ë³´ ì œê³µ"""
    logger.info("ðŸ“ ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼")
    
    service_status = "ready" if prediction_service and prediction_service.is_ready else "initializing"
    predictions_count = 0
    if prediction_service and prediction_service.predictions:
        predictions_count = prediction_service.predictions['sample_count']
        
    return {
        "message": "ðŸŽ¬ Movie Rating Prediction API",
        "version": "1.0.0",
        "status": "running",
        "service_status": service_status,
        "predictions_available": predictions_count,
        "timestamp": datetime.now().isoformat(),
        "endpoints": {
            "health": "/health",
            "predictions": "/predictions", 
            "top_movies": "/top-movies",
            "statistics": "/stats",
            "service_status": "/predict-status",
            "docs": "/docs"
        },
        "description": "MLflow + XGBoost ê¸°ë°˜ ì˜í™” í‰ì  ì˜ˆì¸¡ ì„œë¹„ìŠ¤"
    }

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    logger.info("ðŸ’Š í—¬ìŠ¤ì²´í¬ ìš”ì²­ ìˆ˜ì‹ ")
    
    if not prediction_service:
        return {
            "status": "starting",
            "timestamp": datetime.now().isoformat(),
            "message": "ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘..."
        }
    
    service_status = prediction_service.get_status()
    overall_status = "healthy" if service_status['service_ready'] else "unhealthy"
    
    return {
        "status": overall_status,
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0",
        "service_details": {
            "service_ready": service_status['service_ready'],
            "model_loaded": service_status['model_loaded'],
            "data_loaded": service_status['data_loaded'],
            "predictions_available": service_status['predictions_available'],
            "sample_count": service_status['sample_count']
        },
        "message": "ì˜í™” í‰ì  ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ìƒíƒœ"
    }

# ì˜ˆì¸¡ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
@app.get("/predictions")
async def get_all_predictions():
    """ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ì¡°íšŒ"""
    if not prediction_service:
        raise HTTPException(status_code=503, detail="ì˜ˆì¸¡ ì„œë¹„ìŠ¤ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    if not prediction_service.is_ready:
        raise HTTPException(status_code=503, detail="ì˜ˆì¸¡ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        predictions = prediction_service.get_predictions()
        
        if not predictions['available']:
            raise HTTPException(status_code=404, detail="ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"ðŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ì¡°íšŒ: {predictions['sample_count']:,}ê°œ")
        
        return {
            "success": True,
            "message": f"{predictions['sample_count']:,}ê°œ ì˜í™” ì˜ˆì¸¡ ê²°ê³¼",
            "timestamp": datetime.now().isoformat(),
            "data": {
                "total_count": predictions['sample_count'],
                "predictions": predictions['results']
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì˜ˆì¸¡ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/top-movies")
async def get_top_movies(limit: int = Query(default=10, ge=1, le=50, description="ìƒìœ„ ëª‡ ê°œ ì˜í™”ë¥¼ ê°€ì ¸ì˜¬ì§€")):
    """ì˜ˆì¸¡ í‰ì  ìƒìœ„ ì˜í™” ì¡°íšŒ"""
    if not prediction_service:
        raise HTTPException(status_code=503, detail="ì˜ˆì¸¡ ì„œë¹„ìŠ¤ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    if not prediction_service.is_ready:
        raise HTTPException(status_code=503, detail="ì˜ˆì¸¡ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        top_movies = prediction_service.get_top_movies(limit)
        
        if not top_movies['available']:
            raise HTTPException(status_code=404, detail="ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"ðŸ† ìƒìœ„ {limit}ê°œ ì˜í™” ì¡°íšŒ")
        
        return {
            "success": True,
            "message": f"ì˜ˆì¸¡ í‰ì  ìƒìœ„ {limit}ê°œ ì˜í™”",
            "timestamp": datetime.now().isoformat(),
            "data": {
                "top_movies": top_movies['top_movies'],
                "total_movies": top_movies['total_count'],
                "showing_count": len(top_movies['top_movies'])
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ìƒìœ„ ì˜í™” ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ìƒìœ„ ì˜í™” ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/stats")
async def get_prediction_statistics():
    """ì˜ˆì¸¡ í†µê³„ ì •ë³´ ì¡°íšŒ"""
    if not prediction_service:
        raise HTTPException(status_code=503, detail="ì˜ˆì¸¡ ì„œë¹„ìŠ¤ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    if not prediction_service.is_ready:
        raise HTTPException(status_code=503, detail="ì˜ˆì¸¡ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        predictions = prediction_service.get_predictions()
        
        if not predictions['available']:
            raise HTTPException(status_code=404, detail="ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # í†µê³„ ê³„ì‚°
        ratings = [result['predicted_rating'] for result in predictions['results']]
        
        import statistics
        stats = {
            "total_movies": len(ratings),
            "average_rating": round(statistics.mean(ratings), 2),
            "max_rating": round(max(ratings), 2),
            "min_rating": round(min(ratings), 2),
            "median_rating": round(statistics.median(ratings), 2),
            "std_deviation": round(statistics.stdev(ratings), 2) if len(ratings) > 1 else 0
        }
        
        # í‰ì  êµ¬ê°„ë³„ ë¶„í¬
        rating_bins = {
            "8.0_ì´ìƒ": len([r for r in ratings if r >= 8.0]),
            "7.0_8.0": len([r for r in ratings if 7.0 <= r < 8.0]),
            "6.0_7.0": len([r for r in ratings if 6.0 <= r < 7.0]),
            "5.0_6.0": len([r for r in ratings if 5.0 <= r < 6.0]),
            "5.0_ë¯¸ë§Œ": len([r for r in ratings if r < 5.0])
        }
        
        logger.info("ðŸ“ˆ ì˜ˆì¸¡ í†µê³„ ì¡°íšŒ")
        
        return {
            "success": True,
            "message": "ì˜ˆì¸¡ í†µê³„ ì •ë³´",
            "timestamp": datetime.now().isoformat(),
            "data": {
                "statistics": stats,
                "distribution": rating_bins
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/predict-status")
async def get_prediction_service_status():
    """ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ìƒíƒœ ì¡°íšŒ"""
    if not prediction_service:
        return {
            "service_available": False,
            "message": "ì˜ˆì¸¡ ì„œë¹„ìŠ¤ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "timestamp": datetime.now().isoformat()
        }
    
    try:
        status = prediction_service.get_status()
        
        return {
            "service_available": True,
            "status": status,
            "timestamp": datetime.now().isoformat(),
            "message": "ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´"
        }
        
    except Exception as e:
        logger.error(f"âŒ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# ê°œë°œìš© ì„œë²„ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    logger.info("ðŸŽ¬ Movie Rating Prediction FastAPI ì„œë²„ ì‹œìž‘")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=False,  # ë¡œê¹… ì•ˆì •ì„±ì„ ìœ„í•´ reload ë¹„í™œì„±í™”
        log_level="info",
        access_log=True,
    )