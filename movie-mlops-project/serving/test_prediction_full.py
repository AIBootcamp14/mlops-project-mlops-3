import logging
import sys
import os

# ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from services.prediction_service import SimplePredictionService

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

def test_full_prediction_workflow():
    """ì „ì²´ ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ì „ì²´ ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ì„œë¹„ìŠ¤ ìƒì„± ë° ì´ˆê¸°í™”
    print("1ï¸âƒ£ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”...")
    service = SimplePredictionService()
    
    init_result = service.initialize()
    if not init_result['success']:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {init_result['message']}")
        return False
    
    print(f"âœ… ì´ˆê¸°í™” ì„±ê³µ!")
    print(f"   ëª¨ë¸ ë²„ì „: {init_result.get('model_version')}")
    print(f"   ì˜í™” ë°ì´í„°: {init_result.get('data_count')}ê°œ")
    
    # ì „ì²´ ì˜ˆì¸¡ ì‹¤í–‰
    print(f"\n2ï¸âƒ£ ì „ì²´ ì˜í™” ì˜ˆì¸¡ ì‹¤í–‰...")
    pred_result = service.predict_all()
    
    if not pred_result['success']:
        print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {pred_result['message']}")
        return False
    
    print(f"âœ… ì˜ˆì¸¡ ì„±ê³µ!")
    print(f"   ì˜ˆì¸¡ ì™„ë£Œ: {pred_result['sample_count']}ê°œ ì˜í™”")
    
    # ì˜ˆì¸¡ ê²°ê³¼ ì¡°íšŒ
    print(f"\n3ï¸âƒ£ ì˜ˆì¸¡ ê²°ê³¼ ì¡°íšŒ...")
    predictions = service.get_predictions()
    
    if not predictions['available']:
        print(f"âŒ ì˜ˆì¸¡ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {predictions['message']}")
        return False
    
    print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì¡°íšŒ ì„±ê³µ!")
    print(f"   ì´ ì˜ˆì¸¡ ê²°ê³¼: {predictions['sample_count']}ê°œ")
    
    # ìƒìœ„ 10ê°œ ì˜í™” ì¡°íšŒ
    print(f"\n4ï¸âƒ£ ì˜ˆì¸¡ í‰ì  ìƒìœ„ 10ê°œ ì˜í™”...")
    top_movies = service.get_top_movies(10)
    
    if not top_movies['available']:
        print(f"âŒ ìƒìœ„ ì˜í™” ì¡°íšŒ ì‹¤íŒ¨: {top_movies['message']}")
        return False
    
    print(f"âœ… ìƒìœ„ ì˜í™” ì¡°íšŒ ì„±ê³µ!")
    print(f"\nğŸ† ì˜ˆì¸¡ í‰ì  TOP 10:")
    for movie in top_movies['top_movies']:
        print(f"   {movie['rank']:2d}. ì˜í™” ID {movie['movie_id']:6d}: {movie['predicted_rating']:.2f}")
    
    # ì˜ˆì¸¡ í†µê³„
    print(f"\n5ï¸âƒ£ ì˜ˆì¸¡ í†µê³„...")
    ratings = [result['predicted_rating'] for result in predictions['results']]
    
    import statistics
    avg_rating = statistics.mean(ratings)
    max_rating = max(ratings)
    min_rating = min(ratings)
    
    print(f"   í‰ê·  ì˜ˆì¸¡ í‰ì : {avg_rating:.2f}")
    print(f"   ìµœê³  ì˜ˆì¸¡ í‰ì : {max_rating:.2f}")
    print(f"   ìµœì € ì˜ˆì¸¡ í‰ì : {min_rating:.2f}")
    
    # ì„œë¹„ìŠ¤ ìµœì¢… ìƒíƒœ
    print(f"\n6ï¸âƒ£ ì„œë¹„ìŠ¤ ìµœì¢… ìƒíƒœ...")
    status = service.get_status()
    
    print(f"   ì„œë¹„ìŠ¤ ì¤€ë¹„: {'âœ…' if status['service_ready'] else 'âŒ'}")
    print(f"   ëª¨ë¸ ë¡œë“œ: {'âœ…' if status['model_loaded'] else 'âŒ'}")
    print(f"   ë°ì´í„° ë¡œë“œ: {'âœ…' if status['data_loaded'] else 'âŒ'}")
    print(f"   ì˜ˆì¸¡ ì™„ë£Œ: {'âœ…' if status['predictions_available'] else 'âŒ'}")
    print(f"   ì˜ˆì¸¡ ê°œìˆ˜: {status['sample_count']}ê°œ")
    
    print(f"\nğŸ‰ ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    print(f"ğŸ“‹ ì™„ì„±ëœ ê¸°ëŠ¥:")
    print(f"   âœ… ëª¨ë¸ ë¡œë”©")
    print(f"   âœ… ë°ì´í„° ë¡œë”©") 
    print(f"   âœ… ì˜ˆì¸¡ ì‹¤í–‰")
    print(f"   âœ… ê²°ê³¼ ì¡°íšŒ")
    print(f"   âœ… ìƒìœ„ ì˜í™” ì¶”ì¶œ")
    print(f"   âœ… ìƒíƒœ ëª¨ë‹ˆí„°ë§")
    print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: FastAPI ì—°ë™ìœ¼ë¡œ ì›¹ API êµ¬ì¶•")
    
    return True

if __name__ == "__main__":
    test_full_prediction_workflow()